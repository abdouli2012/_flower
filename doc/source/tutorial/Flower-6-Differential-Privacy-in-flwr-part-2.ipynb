{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential Privacy in flwr Part 2\n",
    "## Step by step guide\n",
    "\n",
    "In this tutorial, we will learn the recommended best practices to build an effective differential privacy setting in federated learning using Flower. \n",
    "\n",
    "The documentation will provide a step-by-step guide, code examples, and best practices for implementing user-level differential privacy gurantees in federated learning systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may consider to look at the previous tutorial where we introduced Differential Privacy in federated learning with Flower ([part 1](Flower-5-Differential-Privacy-in-flwr-part-1.ipynb)), the introductory notebook (again, using [Flower](https://flower.dev/) and [PyTorch](https://pytorch.org/))..\n",
    "\n",
    "\n",
    "> [Star Flower on GitHub](https://github.com/adap/flower) ‚≠êÔ∏è and join the Flower community on Slack to connect, ask questions, and get help: [Join Slack](https://flower.dev/join-slack) üåº We'd love to hear from you in the `#introductions` channel! And if anything is unclear, head over to the `#questions` channel.\n",
    "\n",
    "\n",
    "In this notebook, we will demonstrate the recommended best practice for training models with user-level Differential Privacy using.\n",
    " \n",
    "We will train (30 rounds) a model with high trade-off between utility and privacy on the CIFAR-10 training and test set, partition them into ten smaller datasets. If we used more training rounds, we could certainly have a higher-accuracy private model, but not as high as a model trained without DP.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing dependencies\n",
    "\n",
    "Next, we install the necessary packages for PyTorch (`torch` and `torchvision`) and Flower (`flwr`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/flower\n"
     ]
    }
   ],
   "source": [
    "cd ../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///workspaces/flower\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cryptography<42.0.0,>=41.0.2 in /usr/local/lib/python3.10/dist-packages (from flwr==1.5.0) (41.0.3)\n",
      "Requirement already satisfied: grpcio!=1.52.0,<2.0.0,>=1.48.2 in /home/flwr-vscode/.local/lib/python3.10/site-packages (from flwr==1.5.0) (1.51.3)\n",
      "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /home/flwr-vscode/.local/lib/python3.10/site-packages (from flwr==1.5.0) (0.0.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /home/flwr-vscode/.local/lib/python3.10/site-packages (from flwr==1.5.0) (1.25.2)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.19.0 in /home/flwr-vscode/.local/lib/python3.10/site-packages (from flwr==1.5.0) (3.20.3)\n",
      "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /home/flwr-vscode/.local/lib/python3.10/site-packages (from flwr==1.5.0) (3.18.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<42.0.0,>=41.0.2->flwr==1.5.0) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<42.0.0,>=41.0.2->flwr==1.5.0) (2.21)\n",
      "Building wheels for collected packages: flwr\n",
      "  Building editable for flwr (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flwr: filename=flwr-1.5.0-py3-none-any.whl size=9086 sha256=a2fa1e5fbe2225df5f87b0e5a3bb8193854278a115ab68ab70faca6e7f592ffb\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-v_gt_j84/wheels/d4/ef/3f/b808d09666e16dcbbe3c9cbf7f3d223e3acb30348d118fd5d1\n",
      "Successfully built flwr\n",
      "Installing collected packages: flwr\n",
      "  Attempting uninstall: flwr\n",
      "    Found existing installation: flwr 1.5.0\n",
      "    Uninstalling flwr-1.5.0:\n",
      "      Successfully uninstalled flwr-1.5.0\n",
      "Successfully installed flwr-1.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install  flwr[simulation] torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all dependencies installed, we can import everything we need for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu using PyTorch 2.0.1+cu117 and Flower 1.5.0\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import flwr as fl\n",
    "# import tensorflow_privacy as tfp\n",
    "from flwr.common import Metrics\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Downloading and preprocessing the data\n",
    "\n",
    "We will use a convolutional neural network (CNN) on the popular CIFAR-10 dataset (10 Classes) in a Federated Learning setting of 10 clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Setting our constants\n",
    "\n",
    "NUM_CLIENTS = 10\n",
    "BATCH_SIZE = 32\n",
    "NUM_ROUNDS = 15\n",
    "\n",
    "\n",
    "def load_datasets():\n",
    "    # Download and transform CIFAR-10 (train and test)\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # Split training set into 10 partitions to simulate the individual dataset\n",
    "    partition_size = len(trainset) // NUM_CLIENTS\n",
    "    lengths = [partition_size] * NUM_CLIENTS\n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in datasets:\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    return trainloaders, valloaders, testloader\n",
    "\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, Training and Evaluation functions\n",
    "\n",
    "Let's define our model (including `set_parameters` and `get_parameters`), training and test functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flower client\n",
    "\n",
    "We create a subclass of `flwr.client.DPFedAvgNumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`. Here, we also pass the `cid` to the client and use it log additional details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient (fl.client.DPFedAvgNumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "    \n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Strategy customization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DP-FedAvg Modification\n",
    "Originally proposed by McMahan, H. Brendan, et al.,\"Learning differentially private recurrent language models\". DP-FedAvg, has been extended by [Andrew et al. 2021, Differentially Private Learning with Adaptive Clipping](https://arxiv.org/abs/1905.03871), is essentially FedAvg with the following modifications:\n",
    "\n",
    "To guarantee DP at a user-level, we need to apply the following modification in our Federated Averaging algorithm:\n",
    "\n",
    " - **Clipping:**, the clients' model updates must be clipped before transmission to the server, bounding the maximum influence of any one client. Moreover, knowing that the distribution of the update norm has been shown to vary from task-to-task and to evolve as training progresses. Therefore, we will use an adaptive approach of [Andrew et al. 2021, Differentially Private Learning with Adaptive Clipping](#dp-fedavg-modification) that continuously adjusts the clipping threshold to track a prespecified quantile of the update norm distribution.\n",
    " - **Noising:** Gaussian noise must be added by either the server or the clients. Adding noise could degrade the utility of the model, but we can control it using   the standard deviation of the Gaussian noise added to the sum, and the number of sampled clients at each round.\n",
    " >>>> *We provide users with the flexibility to set up the training such that each client independently adds a small amount of noise to the clipped update, with the result that simply aggregating the noisy updates is equivalent to the explicit addition of noise to the non-noisy aggregate at the server.*\n",
    "\n",
    "\n",
    " > *Remarks:* In order to do this, we need first to determine how much noise the model can tolerate with the chosed number of clients (relatively small) per round with fair loss to the model utility. We will eventually train the final model with an increased amount of noise with proportional increased number of clients. \n",
    "\n",
    "### Simplifying assumptions for the training process\n",
    "\n",
    "To ensure that the training process realises the $(\\epsilon, \\delta )$-guarantees at the user-level, we made the following assumptions:\n",
    "\n",
    "-**Fixed-size subsampling** :Fixed-size subsamples of the clients must be taken at each round, as opposed to variable-sized Poisson subsamples.\n",
    "\n",
    "-**Unweighted averaging** : The contributions from all the clients must weighted equally in the aggregate to eliminate the requirement for the server to know in advance the sum of the weights of all clients available for selection.\n",
    "\n",
    "-**No client failures** : The set of available clients must stay constant across all rounds of training. In other words, clients cannot drop out or fail.\n",
    "\n",
    "\n",
    " >*Note:* The dataset should be large enough to support the selected number of clients. It is also important to note that since we are using an adaptative clipping, and the noise multiplier being the ratio of the noise standard deviation to the clipping norm; therefore the magnitude of the noise will change from rounds to rounds. \n",
    " >>*The above assumptions are in line with the contraints imposed by [Andrew et al.](#dp-fedavg-modification)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-08-15 21:52:03,458 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2023-08-15 21:52:07,458\tWARNING services.py:1826 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.51gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-08-15 21:52:07,575\tINFO worker.py:1636 -- Started a local Ray instance.\n",
      "INFO flwr 2023-08-15 21:52:08,381 | app.py:179 | Flower VCE: Ray initialized with resources: {'CPU': 4.0, 'node:172.16.5.4': 1.0, 'object_store_memory': 4398966374.0, 'memory': 8797932750.0}\n",
      "INFO flwr 2023-08-15 21:52:08,382 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2023-08-15 21:52:08,383 | server.py:276 | Requesting initial parameters from one random client\n",
      "INFO flwr 2023-08-15 21:52:10,513 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2023-08-15 21:52:10,514 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2023-08-15 21:52:10,514 | server.py:104 | FL starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=24041)\u001b[0m [Client 9] get_parameters\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'complex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m client_resources \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mnum_cpus\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnum_gpus\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0\u001b[39m}\n\u001b[1;32m     28\u001b[0m \u001b[39m# Start simulation\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m fl\u001b[39m.\u001b[39;49msimulation\u001b[39m.\u001b[39;49mstart_simulation(\n\u001b[1;32m     30\u001b[0m     client_fn\u001b[39m=\u001b[39;49mclient_fn,\n\u001b[1;32m     31\u001b[0m     num_clients\u001b[39m=\u001b[39;49mNUM_CLIENTS,\n\u001b[1;32m     32\u001b[0m     config\u001b[39m=\u001b[39;49mfl\u001b[39m.\u001b[39;49mserver\u001b[39m.\u001b[39;49mServerConfig(num_rounds\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m),  \u001b[39m# Just three rounds\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m     34\u001b[0m     client_resources\u001b[39m=\u001b[39;49mclient_resources,\n\u001b[1;32m     35\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/flower/src/py/flwr/simulation/app.py:196\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised)\u001b[0m\n\u001b[1;32m    193\u001b[0m     initialized_server\u001b[39m.\u001b[39mclient_manager()\u001b[39m.\u001b[39mregister(client\u001b[39m=\u001b[39mclient_proxy)\n\u001b[1;32m    195\u001b[0m \u001b[39m# Start training\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m hist \u001b[39m=\u001b[39m run_fl(\n\u001b[1;32m    197\u001b[0m     server\u001b[39m=\u001b[39;49minitialized_server,\n\u001b[1;32m    198\u001b[0m     config\u001b[39m=\u001b[39;49minitialized_config,\n\u001b[1;32m    199\u001b[0m )\n\u001b[1;32m    201\u001b[0m event(EventType\u001b[39m.\u001b[39mSTART_SIMULATION_LEAVE)\n\u001b[1;32m    203\u001b[0m \u001b[39mreturn\u001b[39;00m hist\n",
      "File \u001b[0;32m/workspaces/flower/src/py/flwr/server/app.py:224\u001b[0m, in \u001b[0;36mrun_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_fl\u001b[39m(\n\u001b[1;32m    220\u001b[0m     server: Server,\n\u001b[1;32m    221\u001b[0m     config: ServerConfig,\n\u001b[1;32m    222\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m History:\n\u001b[1;32m    223\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train a model on the given server and return the History object.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     hist \u001b[39m=\u001b[39m server\u001b[39m.\u001b[39;49mfit(num_rounds\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnum_rounds, timeout\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mround_timeout)\n\u001b[1;32m    225\u001b[0m     log(INFO, \u001b[39m\"\u001b[39m\u001b[39mapp_fit: losses_distributed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(hist\u001b[39m.\u001b[39mlosses_distributed))\n\u001b[1;32m    226\u001b[0m     log(INFO, \u001b[39m\"\u001b[39m\u001b[39mapp_fit: metrics_distributed_fit \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(hist\u001b[39m.\u001b[39mmetrics_distributed_fit))\n",
      "File \u001b[0;32m/workspaces/flower/src/py/flwr/server/server.py:109\u001b[0m, in \u001b[0;36mServer.fit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m start_time \u001b[39m=\u001b[39m timeit\u001b[39m.\u001b[39mdefault_timer()\n\u001b[1;32m    107\u001b[0m \u001b[39mfor\u001b[39;00m current_round \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, num_rounds \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    108\u001b[0m     \u001b[39m# Train model and replace previous global model\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     res_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_round(\n\u001b[1;32m    110\u001b[0m         server_round\u001b[39m=\u001b[39;49mcurrent_round,\n\u001b[1;32m    111\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m res_fit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m         parameters_prime, fit_metrics, _ \u001b[39m=\u001b[39m res_fit  \u001b[39m# fit_metrics_aggregated\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/flower/src/py/flwr/server/server.py:213\u001b[0m, in \u001b[0;36mServer.fit_round\u001b[0;34m(self, server_round, timeout)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Perform a single round of federated averaging.\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m# Get clients and their respective instructions from strategy\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m client_instructions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49mconfigure_fit(\n\u001b[1;32m    214\u001b[0m     server_round\u001b[39m=\u001b[39;49mserver_round,\n\u001b[1;32m    215\u001b[0m     parameters\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparameters,\n\u001b[1;32m    216\u001b[0m     client_manager\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client_manager,\n\u001b[1;32m    217\u001b[0m )\n\u001b[1;32m    219\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m client_instructions:\n\u001b[1;32m    220\u001b[0m     log(INFO, \u001b[39m\"\u001b[39m\u001b[39mfit_round \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: no clients selected, cancel\u001b[39m\u001b[39m\"\u001b[39m, server_round)\n",
      "File \u001b[0;32m/workspaces/flower/src/py/flwr/server/strategy/dpfedavg_adaptive.py:80\u001b[0m, in \u001b[0;36mDPFedAvgAdaptive.configure_fit\u001b[0;34m(self, server_round, parameters, client_manager)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Configure the next round of training.\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m additional_config \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdpfedavg_adaptive_clip_enabled\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m}\n\u001b[0;32m---> 80\u001b[0m client_instructions \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mconfigure_fit(\n\u001b[1;32m     81\u001b[0m     server_round, parameters, client_manager\n\u001b[1;32m     82\u001b[0m )\n\u001b[1;32m     84\u001b[0m \u001b[39mfor\u001b[39;00m _, fit_ins \u001b[39min\u001b[39;00m client_instructions:\n\u001b[1;32m     85\u001b[0m     fit_ins\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mupdate(additional_config)\n",
      "File \u001b[0;32m/workspaces/flower/src/py/flwr/server/strategy/dpfedavg_fixed.py:103\u001b[0m, in \u001b[0;36mDPFedAvgFixed.configure_fit\u001b[0;34m(self, server_round, parameters, client_manager)\u001b[0m\n\u001b[1;32m     99\u001b[0m additional_config \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdpfedavg_clip_norm\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclip_norm}\n\u001b[1;32m    100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mserver_side_noising:\n\u001b[1;32m    101\u001b[0m     additional_config[\n\u001b[1;32m    102\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdpfedavg_noise_stddev\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 103\u001b[0m     ] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calc_client_noise_stddev()\n\u001b[1;32m    105\u001b[0m client_instructions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mconfigure_fit(\n\u001b[1;32m    106\u001b[0m     server_round, parameters, client_manager\n\u001b[1;32m    107\u001b[0m )\n\u001b[1;32m    109\u001b[0m \u001b[39mfor\u001b[39;00m _, fit_ins \u001b[39min\u001b[39;00m client_instructions:\n",
      "File \u001b[0;32m/workspaces/flower/src/py/flwr/server/strategy/dpfedavg_fixed.py:64\u001b[0m, in \u001b[0;36mDPFedAvgFixed._calc_client_noise_stddev\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_calc_client_noise_stddev\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mfloat\u001b[39;49m(\n\u001b[1;32m     65\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnoise_multiplier \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclip_norm \u001b[39m/\u001b[39;49m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_sampled_clients \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m (\u001b[39m0.5\u001b[39;49m))\n\u001b[1;32m     66\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'complex'"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model and get the parameters\n",
    "\n",
    "NUM_SAMPLED_CLIENTS = 5\n",
    "# Pass parameters to the Strategy for server-side parameter initialization\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=0.3,\n",
    "    fraction_evaluate=0.3,\n",
    "    min_fit_clients=3,\n",
    "    min_evaluate_clients=3,\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    ")\n",
    "\n",
    "strategy = fl.server.strategy.DPFedAvgAdaptive(\n",
    "    strategy = strategy ,\n",
    "    num_sampled_clients =  NUM_SAMPLED_CLIENTS,\n",
    "    init_clip_norm = 0.3,\n",
    "    noise_multiplier = 0.9,\n",
    "    server_side_noising = False ,\n",
    "    clip_norm_lr =0.2,\n",
    "    clip_norm_target_quantile = 0.5,\n",
    "    clip_count_stddev = None,\n",
    ")\n",
    "\n",
    "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
    "client_resources = {\"num_cpus\": 1, \"num_gpus\": 0}\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the *$(\\epsilon, \\delta )$-analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_order = 32\n",
    "orders = range(2, max_order + 1)\n",
    "rdp = tfp.compute_rdp_sample_without_replacement(q, z, n, orders)\n",
    "eps, _, _ = tfp.rdp_accountant.get_privacy_spent(rdp, target_delta=delta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
