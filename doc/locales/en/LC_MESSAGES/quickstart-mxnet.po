# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022 Adap GmbH
# This file is distributed under the same license as the Flower package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Flower \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-08-09 15:41+0200\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: en\n"
"Language-Team: en <LL@li.org>\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"

#: ../../source/quickstart-mxnet.rst:5
msgid "Quickstart MXNet"
msgstr ""

#: ../../source/quickstart-mxnet.rst:7
msgid ""
"In this tutorial, we will learn how to train a :code:`Sequential` model "
"on MNIST using Flower and MXNet."
msgstr ""

#: ../../source/quickstart-mxnet.rst:9
msgid ""
"It is recommended to create a virtual environment and run everything "
"within this `virtualenv <https://flower.dev/docs/recommended-env-"
"setup.html>`_."
msgstr ""

#: ../../source/quickstart-mxnet.rst:11
msgid ""
"Our example consists of one *server* and two *clients* all having the "
"same model."
msgstr ""

#: ../../source/quickstart-mxnet.rst:13
msgid ""
"*Clients* are responsible for generating individual model parameter "
"updates for the model based on their local datasets. These updates are "
"then sent to the *server* which will aggregate them to produce an updated"
" global model. Finally, the *server* sends this improved version of the "
"model back to each *client*. A complete cycle of parameters updates is "
"called a *round*."
msgstr ""

#: ../../source/quickstart-mxnet.rst:17
msgid ""
"Now that we have a rough idea of what is going on, let's get started. We "
"first need to install Flower. You can do this by running:"
msgstr ""

#: ../../source/quickstart-mxnet.rst:23
msgid "Since we want to use MXNet, let's go ahead and install it:"
msgstr ""

#: ../../source/quickstart-mxnet.rst:31
msgid "Flower Client"
msgstr ""

#: ../../source/quickstart-mxnet.rst:33
msgid ""
"Now that we have all our dependencies installed, let's run a simple "
"distributed training with two clients and one server. Our training "
"procedure and network architecture are based on MXNetÂ´s `Hand-written "
"Digit Recognition tutorial "
"<https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/image/mnist.html>`_."
msgstr ""

#: ../../source/quickstart-mxnet.rst:35
msgid ""
"In a file called :code:`client.py`, import Flower and MXNet related "
"packages:"
msgstr ""

#: ../../source/quickstart-mxnet.rst:50
msgid "In addition, define the device allocation in MXNet with:"
msgstr ""

#: ../../source/quickstart-mxnet.rst:56
msgid ""
"We use MXNet to load MNIST, a popular image classification dataset of "
"handwritten digits for machine learning. The MXNet utility "
":code:`mx.test_utils.get_mnist()` downloads the training and test data."
msgstr ""

#: ../../source/quickstart-mxnet.rst:70
msgid ""
"Define the training and loss with MXNet. We train the model by looping "
"over the dataset, measure the corresponding loss, and optimize it."
msgstr ""

#: ../../source/quickstart-mxnet.rst:108
msgid ""
"Next, we define the validation of our machine learning model. We loop "
"over the test set and measure both loss and accuracy on the test set."
msgstr ""

#: ../../source/quickstart-mxnet.rst:132
msgid ""
"After defining the training and testing of a MXNet machine learning "
"model, we use these functions to implement a Flower client."
msgstr ""

#: ../../source/quickstart-mxnet.rst:134
msgid "Our Flower clients will use a simple :code:`Sequential` model:"
msgstr ""

#: ../../source/quickstart-mxnet.rst:153
msgid ""
"After loading the dataset with :code:`load_data()` we perform one forward"
" propagation to initialize the model and model parameters with "
":code:`model(init)`. Next, we implement a Flower client."
msgstr ""

#: ../../source/quickstart-mxnet.rst:155
msgid ""
"The Flower server interacts with clients through an interface called "
":code:`Client`. When the server selects a particular client for training,"
" it sends training instructions over the network. The client receives "
"those instructions and calls one of the :code:`Client` methods to run "
"your code (i.e., to train the neural network we defined earlier)."
msgstr ""

#: ../../source/quickstart-mxnet.rst:161
msgid ""
"Flower provides a convenience class called :code:`NumPyClient` which "
"makes it easier to implement the :code:`Client` interface when your "
"workload uses MXNet. Implementing :code:`NumPyClient` usually means "
"defining the following methods (:code:`set_parameters` is optional "
"though):"
msgstr ""

#: ../../source/quickstart-mxnet.rst:166
msgid ":code:`get_parameters`"
msgstr ""

#: ../../source/quickstart-mxnet.rst:167
msgid "return the model weight as a list of NumPy ndarrays"
msgstr ""

#: ../../source/quickstart-mxnet.rst:168
msgid ":code:`set_parameters` (optional)"
msgstr ""

#: ../../source/quickstart-mxnet.rst:169
msgid ""
"update the local model weights with the parameters received from the "
"server"
msgstr ""

#: ../../source/quickstart-mxnet.rst:172
msgid ":code:`fit`"
msgstr ""

#: ../../source/quickstart-mxnet.rst:171
msgid "set the local model weights"
msgstr ""

#: ../../source/quickstart-mxnet.rst:172
msgid "train the local model"
msgstr ""

#: ../../source/quickstart-mxnet.rst:173
msgid "receive the updated local model weights"
msgstr ""

#: ../../source/quickstart-mxnet.rst:175
msgid ":code:`evaluate`"
msgstr ""

#: ../../source/quickstart-mxnet.rst:175
msgid "test the local model"
msgstr ""

#: ../../source/quickstart-mxnet.rst:177
msgid "They can be implemented in the following way:"
msgstr ""

#: ../../source/quickstart-mxnet.rst:207
msgid ""
"We can now create an instance of our class :code:`MNISTClient` and add "
"one line to actually run this client:"
msgstr ""

#: ../../source/quickstart-mxnet.rst:214
msgid ""
"That's it for the client. We only have to implement :code:`Client` or "
":code:`NumPyClient` and call :code:`fl.client.start_client()` or "
":code:`fl.client.start_numpy_client()`. The string "
":code:`\"0.0.0.0:8080\"` tells the client which server to connect to. In "
"our case we can run the server and the client on the same machine, "
"therefore we use :code:`\"0.0.0.0:8080\"`. If we run a truly federated "
"workload with the server and clients running on different machines, all "
"that needs to change is the :code:`server_address` we pass to the client."
msgstr ""

#: ../../source/quickstart-mxnet.rst:221
msgid "Flower Server"
msgstr ""

#: ../../source/quickstart-mxnet.rst:223
msgid ""
"For simple workloads we can start a Flower server and leave all the "
"configuration possibilities at their default values. In a file named "
":code:`server.py`, import Flower and start the server:"
msgstr ""

#: ../../source/quickstart-mxnet.rst:234
msgid "Train the model, federated!"
msgstr ""

#: ../../source/quickstart-mxnet.rst:236
msgid ""
"With both client and server ready, we can now run everything and see "
"federated learning in action. Federated learning systems usually have a "
"server and multiple clients. We therefore have to start the server first:"
msgstr ""

#: ../../source/quickstart-mxnet.rst:244
msgid ""
"Once the server is running we can start the clients in different "
"terminals. Open a new terminal and start the first client:"
msgstr ""

#: ../../source/quickstart-mxnet.rst:251
msgid "Open another terminal and start the second client:"
msgstr ""

#: ../../source/quickstart-mxnet.rst:257
msgid ""
"Each client will have its own dataset. You should now see how the "
"training does in the very first terminal (the one that started the "
"server):"
msgstr ""

#: ../../source/quickstart-mxnet.rst:289
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system. The full `source code "
"<https://github.com/adap/flower/blob/main/examples/quickstart-"
"mxnet/client.py>`_ for this example can be found in :code:`examples"
"/quickstart-mxnet`."
msgstr ""

