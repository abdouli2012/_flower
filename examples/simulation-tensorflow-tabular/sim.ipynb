{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flower Quickstart (Simulation with TensorFlow/Keras on tabular data)\n",
    "\n",
    "Welcome to Flower, a friendly federated learning framework!\n",
    "\n",
    "In this notebook, we'll simulate a federated learning system with 5 clients. The clients will use TensorFlow/Keras on tabular data to define model training and evaluation. Let's start by installing Flower (published as `flwr` on PyPI) with the `simulation` extra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q flwr[\"simulation\"] tensorflow\n",
    "!pip install -q flwr_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also install Matplotlib, Pandas and Scikit-learn so we can make some plots once the simulation is completed, use dataframes and get data processing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib pandas scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the required dependencies. The most important imports are Flower (`flwr`) and TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "from flwr.simulation.ray_transport.utils import enable_tf_gpu_growth\n",
    "\n",
    "from datasets import Dataset\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import DirichletPartitioner\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "VERBOSE = 0\n",
    "NUM_CLIENTS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Define Alpha to use for DirichletPartitioner\n",
    "ALPHA = 1000\n",
    "\n",
    "# Define features to employ\n",
    "RELEVANT_FEATURES = ['Pclass', 'Sex', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining the model we want to federated. Since we will be working with Titanic, using a fully connected model is sufficient. You can of course customize this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_features):\n",
    "    \"\"\"Constructs a simple model architecture suitable for Titanic dataset.\"\"\"\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(32, input_dim=num_features, activation='relu'),\n",
    "            tf.keras.layers.Dense(16, activation='relu'),\n",
    "            tf.keras.layers.Dense(8, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that out of the way, let's move on to the interesting bits. Federated learning systems consist of a server and multiple clients. In Flower, we create clients by implementing subclasses of `flwr.client.Client` or `flwr.client.NumPyClient`. We use `NumPyClient` in this tutorial because it is easier to implement and requires us to write less boilerplate.\n",
    "\n",
    "To implement the Flower client, we create a subclass of `flwr.client.NumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`:\n",
    "\n",
    "- `get_parameters`: Return the current local model parameters\n",
    "- `fit`: Receive model parameters from the server, train the model parameters on the local data, and return the (updated) model parameters to the server \n",
    "- `evaluate`: Received model parameters from the server, evaluate the model parameters on the local data, and return the evaluation result to the server\n",
    "\n",
    "We mentioned that our clients will use TensorFlow/Keras for the model training and evaluation. Keras models provide methods that make the implementation straightforward: we can update the local model with server-provides parameters through `model.set_weights`, we can train/evaluate the model through `fit/evaluate`, and we can get the updated model parameters through `model.get_weights`.\n",
    "\n",
    "Let's see a simple implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, trainset, valset, num_features) -> None:\n",
    "        # Create model\n",
    "        self.model = get_model(num_features)\n",
    "        self.trainset = trainset\n",
    "        self.valset = valset\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        self.model.fit(self.trainset, epochs=1, verbose=VERBOSE)\n",
    "        return self.model.get_weights(), len(self.trainset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        loss, acc = self.model.evaluate(self.valset, verbose=VERBOSE)\n",
    "        return loss, len(self.valset), {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our class `FlowerClient` defines how local training/evaluation will be performed and allows Flower to call the local training/evaluation through `fit` and `evaluate`. Each instance of `FlowerClient` represents a *single client* in our federated learning system. Federated learning systems have multiple clients (otherwise, there's not much to federate, is there?), so each client will be represented by its own instance of `FlowerClient`. If we have, for example, three clients in our workload, we'd have three instances of `FlowerClient`. Flower calls `FlowerClient.fit` on the respective instance when the server selects a particular client for training (and `FlowerClient.evaluate` for evaluation).\n",
    "\n",
    "In this notebook, we want to simulate a federated learning system with 5 clients on a single machine. This means that the server and all 5 clients will live on a single machine and share resources such as CPU, GPU, and memory. Having 5 clients would mean having 5 instances of `FlowerClient` in memory. Doing this on a single machine can quickly exhaust the available memory resources, even if only a subset of these clients participates in a single round of federated learning.\n",
    "\n",
    "In addition to the regular capabilities where server and clients run on multiple machines, Flower, therefore, provides special simulation capabilities that create `FlowerClient` instances only when they are actually necessary for training or evaluation. To enable the Flower framework to create clients when necessary, we need to implement a function called `client_fn` that creates a `FlowerClient` instance on demand. Flower calls `client_fn` whenever it needs an instance of one particular client to call `fit` or `evaluate` (those instances are usually discarded after use). Clients are identified by a client ID, or short `cid`. The `cid` can be used, for example, to load different local data partitions for each client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define three auxiliary functions for this example (note the last two are entirely optional):\n",
    "* `get_client_fn()`: Is a function that returns another function. The returned `client_fn` will be executed by Flower's VirtualClientEngine each time a new _virtual_ client (i.e. a client that is simulated in a Python process) needs to be spawn. When are virtual clients spawned? Each time the strategy samples them to do either `fit()` (i.e. train the global model on the local data of a particular client) or `evaluate()` (i.e. evaluate the global model on the validation set of a given client).\n",
    "\n",
    "* `weighted_average()`: This is an optional function to pass to the strategy. It will be executed after an evaluation round (i.e. when client run `evaluate()`) and will aggregate the metrics clients return. In this example, we use this function to compute the weighted average accuracy of clients doing `evaluate()`.\n",
    "\n",
    "* `get_evaluate_fn()`: This is again a function that returns another function. The returned function will be executed by the strategy at the end of a `fit()` round and after a new global model has been obtained after aggregation. This is an optional argument for Flower strategies. In this example, we use the a Titanic test set (extracted using `sklearn.model_selection.train_test_split`) to perform this server-side evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_fn(dataset: FederatedDataset):\n",
    "    \"\"\"Return a function to construct a client.\n",
    "\n",
    "    The VirtualClientEngine will execute this function whenever a client is sampled by\n",
    "    the strategy to participate.\n",
    "    \"\"\"\n",
    "\n",
    "    def client_fn(cid: str) -> fl.client.Client:\n",
    "        \"\"\"Construct a FlowerClient with its own dataset partition.\"\"\"\n",
    "\n",
    "        # Extract partition for client with id = cid\n",
    "        client_dataset = dataset.load_partition(int(cid))\n",
    "\n",
    "        # Now let's split it into train (90%) and validation (10%)\n",
    "        client_dataset_splits = client_dataset.train_test_split(test_size=0.1, seed=RANDOM_STATE)\n",
    "\n",
    "        trainset = client_dataset_splits[\"train\"].to_tf_dataset(\n",
    "            columns=\"features\", label_cols=\"labels\", batch_size=64\n",
    "        )\n",
    "\n",
    "        valset = client_dataset_splits[\"test\"].to_tf_dataset(\n",
    "            columns=\"features\", label_cols=\"labels\", batch_size=64\n",
    "        )\n",
    "\n",
    "        # Extract the number of features\n",
    "        element_spec = trainset.element_spec\n",
    "        num_features = element_spec[0].shape[1]\n",
    "\n",
    "        # Create and return client\n",
    "        return FlowerClient(trainset, valset, num_features).to_client()\n",
    "\n",
    "    return client_fn\n",
    "\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n",
    "    the client's evaluate() method.\"\"\"\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "\n",
    "def get_evaluate_fn(testset: Dataset):\n",
    "    \"\"\"Return an evaluation function for server-side (i.e. centralised) evaluation.\"\"\"\n",
    "\n",
    "    # The `evaluate` function will be called after every round by the strategy\n",
    "    def evaluate(\n",
    "        server_round: int,\n",
    "        parameters: fl.common.NDArrays,\n",
    "        config: Dict[str, fl.common.Scalar],\n",
    "    ):\n",
    "        # Extract the number of features\n",
    "        element_spec = testset.element_spec\n",
    "        num_features = element_spec[0].shape[1]\n",
    "\n",
    "        model = get_model(num_features)  # Construct the model\n",
    "        model.set_weights(parameters)  # Update model with the latest parameters\n",
    "        loss, accuracy = model.evaluate(testset, verbose=VERBOSE)\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have `FlowerClient` which defines client-side training and evaluation, and `client_fn`, which allows Flower to create `FlowerClient` instances whenever it needs to call `fit` or `evaluate` on one particular client. The last step is to start the actual simulation using `flwr.simulation.start_simulation`. \n",
    "\n",
    "The function `start_simulation` accepts a number of arguments, amongst them the `client_fn` used to create `FlowerClient` instances, the number of clients to simulate `num_clients`, the number of rounds `num_rounds`, and the strategy. The strategy encapsulates the federated learning approach/algorithm, for example, *Federated Averaging* (FedAvg).\n",
    "\n",
    "Flower comes with a number of built-in strategies, but we can also use our own strategy implementations to customize nearly all aspects of the federated learning approach. For this example, we use the built-in `FedAvg` implementation and customize it using a few basic parameters. The last step is the actual call to `start_simulation` which - you guessed it - actually starts the simulation.\n",
    "\n",
    "We can use [Flower Datasets](https://flower.ai/docs/datasets/) to partition effortlessly obtain an off-the-shelf partitioned dataset or partition one that isn't pre-partitioned. Since we are using the Titanic dataset (which is not part of the Flower Datasets suite), we download it from [Hugging Face](https://huggingface.co/datasets/julien-c/titanic-survival) and the partition it using the `DirichletPartitioner`.\n",
    "\n",
    "Notice that when working with tabular datasets you may need to preprocess (select features, impute missing values, scale the data, etc.). To this purpose we define the `preprocess_data` function which is employed over the Titanic dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "def preprocess_data(data):\n",
    "    \"\"\"Preprocess the dataset.\"\"\"\n",
    "    # Select relevant features\n",
    "    features = data[RELEVANT_FEATURES].copy()\n",
    "    \n",
    "    # Convert 'Sex' to binary values\n",
    "    features['Sex'] = features['Sex'].map({'male': 0, 'female': 1})\n",
    "    \n",
    "    # Fill missing 'Age' values with the mean age\n",
    "    val_miss_age = features['Age'].mean()\n",
    "    features['Age'].fillna(val_miss_age, inplace=True)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    features = pd.DataFrame(scaler.fit_transform(features), columns=RELEVANT_FEATURES)\n",
    "\n",
    "    data = pd.concat([features,data['Survived']], axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from Hugging Face\n",
    "titanic_cds = load_dataset(\"julien-c/titanic-survival\")\n",
    "\n",
    "# Convert to pandas to preprocess\n",
    "titanic_cds = titanic_cds['train'].to_pandas()\n",
    "titanic_cds = preprocess_data(titanic_cds)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "Xy_train, Xy_test = train_test_split(titanic_cds, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=30, no round_timeout\n",
      "2024-06-07 12:06:16,746\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 16.0, 'GPU': 1.0, 'object_store_memory': 1739180851.0, 'node:127.0.0.1': 1.0, 'memory': 3478361703.0, 'node:__internal_head__': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 16 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=48732)\u001b[0m 2024-06-07 12:06:41.046853: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=48732)\u001b[0m To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 0.6846967935562134, {'accuracy': 0.6067415475845337}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.6782386302947998, {'accuracy': 0.6123595237731934}, 3.5417975000000297)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.6718982458114624, {'accuracy': 0.6516854166984558}, 6.360168999999587)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.6658048033714294, {'accuracy': 0.6629213690757751}, 9.104428200000257)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 0.6599589586257935, {'accuracy': 0.6797752976417542}, 11.754328999999416)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=18472)\u001b[0m WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x0000014325871430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=18472)\u001b[0m 2024-06-07 12:06:43.048211: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=18472)\u001b[0m To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 0.6541556119918823, {'accuracy': 0.7022472023963928}, 14.303098200000022)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (6, 0.6482726335525513, {'accuracy': 0.7022472023963928}, 16.883262999999715)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (7, 0.6423869729042053, {'accuracy': 0.7134831547737122}, 19.50253470000098)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (8, 0.636671781539917, {'accuracy': 0.7247191071510315}, 22.1736118000008)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=48732)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x000001C24C951CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=43760)\u001b[0m WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x000001B310FAF670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (9, 0.6310802698135376, {'accuracy': 0.7303370833396912}, 24.97415759999967)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (10, 0.625730037689209, {'accuracy': 0.7359550595283508}, 27.810587100000703)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 11]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=48732)\u001b[0m WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x000001C24B638C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (11, 0.6206838488578796, {'accuracy': 0.7303370833396912}, 30.793032100000346)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 12]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (12, 0.6158028244972229, {'accuracy': 0.7247191071510315}, 33.401710100000855)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 13]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=18472)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x00000143246B51F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (13, 0.6110740303993225, {'accuracy': 0.7247191071510315}, 35.97009919999982)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 14]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (14, 0.6065037846565247, {'accuracy': 0.7247191071510315}, 38.99559079999926)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=12996)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x000001ADDEBA0DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 15]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (15, 0.6017972826957703, {'accuracy': 0.7247191071510315}, 41.72582280000097)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 16]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (16, 0.5969423055648804, {'accuracy': 0.7191011309623718}, 44.57774840000093)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 17]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=12996)\u001b[0m WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x000001ADE2152280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (17, 0.5921147465705872, {'accuracy': 0.7247191071510315}, 47.738011900000856)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 18]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (18, 0.5873023271560669, {'accuracy': 0.7247191071510315}, 50.75007320000077)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 19]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (19, 0.5825494527816772, {'accuracy': 0.7191011309623718}, 53.84743619999972)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 20]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (20, 0.5778329372406006, {'accuracy': 0.7191011309623718}, 56.547303600000305)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 21]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (21, 0.5731101632118225, {'accuracy': 0.7247191071510315}, 59.29831279999962)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 22]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (22, 0.5684714317321777, {'accuracy': 0.7303370833396912}, 61.92603050000071)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 23]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (23, 0.5640119314193726, {'accuracy': 0.7303370833396912}, 64.56069220000063)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 24]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (24, 0.5596384406089783, {'accuracy': 0.7415730357170105}, 67.25057609999931)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 25]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (25, 0.5554856061935425, {'accuracy': 0.7415730357170105}, 69.99868140000035)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 26]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (26, 0.5514471530914307, {'accuracy': 0.7359550595283508}, 72.82217069999933)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 27]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (27, 0.5475656986236572, {'accuracy': 0.7415730357170105}, 76.00626960000045)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 28]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (28, 0.5438629984855652, {'accuracy': 0.7415730357170105}, 78.99823110000034)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 29]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (29, 0.5403937101364136, {'accuracy': 0.7415730357170105}, 81.95961779999925)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 30]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (30, 0.5372146368026733, {'accuracy': 0.7359550595283508}, 84.63729570000032)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 30 rounds in 85.21s\n",
      "\u001b[92mINFO \u001b[0m:      History (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t('\\tround 1: 0.6955075562000275\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 2: 0.6620399057865143\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 3: 0.6960256397724152\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 4: 0.6792699992656708\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 5: 0.6304108202457428\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 6: 0.6146054565906525\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 7: 0.6672801673412323\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 8: 0.6478192508220673\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 9: 0.5869075357913971\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 10: 0.5814819633960724\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 11: 0.5716291666030884\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 12: 0.5555524826049805\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 13: 0.5543006956577301\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 14: 0.6148875653743744\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 15: 0.5245926380157471\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 16: 0.5191524028778076\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 17: 0.5206507742404938\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 18: 0.5919952094554901\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 19: 0.500003769993782\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 20: 0.594001442193985\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 21: 0.5698692500591278\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 22: 0.46042904257774353\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 23: 0.5715115815401077\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 24: 0.5509510785341263\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 25: 0.5446596592664719\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 26: 0.4449404627084732\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 27: 0.4271198958158493\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 28: 0.4323571026325226\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 29: 0.42416439950466156\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 30: 0.4015657603740692\\n')History (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t('\\tround 0: 0.6846967935562134\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 1: 0.6782386302947998\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 2: 0.6718982458114624\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 3: 0.6658048033714294\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 4: 0.6599589586257935\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 5: 0.6541556119918823\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 6: 0.6482726335525513\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 7: 0.6423869729042053\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 8: 0.636671781539917\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 9: 0.6310802698135376\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 10: 0.625730037689209\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 11: 0.6206838488578796\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 12: 0.6158028244972229\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 13: 0.6110740303993225\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 14: 0.6065037846565247\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 15: 0.6017972826957703\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 16: 0.5969423055648804\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 17: 0.5921147465705872\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 18: 0.5873023271560669\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 19: 0.5825494527816772\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 20: 0.5778329372406006\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 21: 0.5731101632118225\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 22: 0.5684714317321777\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 23: 0.5640119314193726\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 24: 0.5596384406089783\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 25: 0.5554856061935425\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 26: 0.5514471530914307\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 27: 0.5475656986236572\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 28: 0.5438629984855652\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 29: 0.5403937101364136\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 30: 0.5372146368026733\\n')History (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.6333333402872086),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.6333333551883698),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.5333333611488342),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.7000000178813934),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.7333333492279053),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.800000011920929),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.7000000178813934),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.7642857134342194),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (9, 0.800000011920929),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (10, 0.8976190388202667),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (11, 0.8333333432674408),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (12, 0.8285714387893677),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (13, 0.8333333432674408),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (14, 0.7285714447498322),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (15, 0.8333333432674408),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (16, 0.8285714387893677),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (17, 0.8666666746139526),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (18, 0.7333333492279053),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (19, 0.8666666746139526),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (20, 0.7333333492279053),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (21, 0.7000000178813934),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (22, 0.8666666746139526),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (23, 0.6952381134033203),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (24, 0.7000000178813934),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (25, 0.6666666865348816),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (26, 0.8261904716491699),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (27, 0.9000000059604645),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (28, 0.9000000059604645),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (29, 0.8619047701358795),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (30, 0.8619047701358795)]}History (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(0, 0.6067415475845337),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (1, 0.6123595237731934),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.6516854166984558),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.6629213690757751),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.6797752976417542),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.7022472023963928),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.7022472023963928),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.7134831547737122),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.7247191071510315),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (9, 0.7303370833396912),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (10, 0.7359550595283508),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (11, 0.7303370833396912),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (12, 0.7247191071510315),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (13, 0.7247191071510315),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (14, 0.7247191071510315),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (15, 0.7247191071510315),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (16, 0.7191011309623718),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (17, 0.7247191071510315),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (18, 0.7247191071510315),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (19, 0.7191011309623718),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (20, 0.7191011309623718),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (21, 0.7247191071510315),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (22, 0.7303370833396912),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (23, 0.7303370833396912),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (24, 0.7415730357170105),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (25, 0.7415730357170105),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (26, 0.7359550595283508),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (27, 0.7415730357170105),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (28, 0.7415730357170105),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (29, 0.7415730357170105),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (30, 0.7359550595283508)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    }
   ],
   "source": [
    "# Enable GPU growth in your main process\n",
    "enable_tf_gpu_growth()\n",
    "\n",
    "# Set train and test data in Dataset format\n",
    "train_cds = {\"features\": Xy_train[RELEVANT_FEATURES].values.tolist(), \"labels\": Xy_train[\"Survived\"].values.tolist()}\n",
    "train_cds = pd.DataFrame(train_cds)\n",
    "train_cds = Dataset.from_pandas(train_cds)\n",
    "\n",
    "centralized_testset = {\"features\": Xy_test[RELEVANT_FEATURES].values.tolist(), \"labels\": Xy_test[\"Survived\"].values.tolist()}\n",
    "centralized_testset = pd.DataFrame(centralized_testset)\n",
    "centralized_testset = Dataset.from_pandas(centralized_testset).to_tf_dataset(\n",
    "    columns=\"features\", label_cols=\"labels\", batch_size=64\n",
    ")\n",
    "\n",
    "# Set partitioner to federate data\n",
    "partitioner = DirichletPartitioner(num_partitions=NUM_CLIENTS, partition_by=\"labels\", alpha=ALPHA)\n",
    "partitioner.dataset = train_cds\n",
    "\n",
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "    fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
    "    min_fit_clients=2,  # Never sample less than 2 clients for training\n",
    "    min_evaluate_clients=2,  # Never sample less than 2 clients for evaluation\n",
    "    min_available_clients=int(\n",
    "        NUM_CLIENTS * 0.75\n",
    "    ),  # Wait until at least 75 clients are available\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,  # aggregates federated metrics\n",
    "    evaluate_fn=get_evaluate_fn(centralized_testset),  # global evaluation function\n",
    ")\n",
    "\n",
    "# With a dictionary, you tell Flower's VirtualClientEngine that each\n",
    "# client needs exclusive access to these many resources in order to run\n",
    "client_resources = {\"num_cpus\": 1, \"num_gpus\": 0.0}\n",
    "\n",
    "# Start simulation\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=get_client_fn(partitioner),\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=30),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    "    actor_kwargs={\n",
    "        \"on_actor_init_fn\": enable_tf_gpu_growth  # Enable GPU growth upon actor init.\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then use the resturned History object to either save the results to disk or do some visualisation (or both of course, or neither if you like chaos). Below you can see how you can plot the centralised accuracy obtainined at the end of each round (including at the very beginning of the experiment) for the global model. This is want the function `evaluate_fn()` that we passed to the strategy reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history.metrics_centralized = {'accuracy': [(0, 0.6067415475845337), (1, 0.6123595237731934), (2, 0.6516854166984558), (3, 0.6629213690757751), (4, 0.6797752976417542), (5, 0.7022472023963928), (6, 0.7022472023963928), (7, 0.7134831547737122), (8, 0.7247191071510315), (9, 0.7303370833396912), (10, 0.7359550595283508), (11, 0.7303370833396912), (12, 0.7247191071510315), (13, 0.7247191071510315), (14, 0.7247191071510315), (15, 0.7247191071510315), (16, 0.7191011309623718), (17, 0.7247191071510315), (18, 0.7247191071510315), (19, 0.7191011309623718), (20, 0.7191011309623718), (21, 0.7247191071510315), (22, 0.7303370833396912), (23, 0.7303370833396912), (24, 0.7415730357170105), (25, 0.7415730357170105), (26, 0.7359550595283508), (27, 0.7415730357170105), (28, 0.7415730357170105), (29, 0.7415730357170105), (30, 0.7359550595283508)]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Titanic - IID - 5 clients with 5 clients per round')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"{history.metrics_centralized = }\")\n",
    "\n",
    "global_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\n",
    "round = [data[0] for data in global_accuracy_centralised]\n",
    "acc = [100.0 * data[1] for data in global_accuracy_centralised]\n",
    "plt.plot(round, acc)\n",
    "plt.grid()\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.title(\"Titanic - IID - \"+str(NUM_CLIENTS)+\" clients with 5 clients per round\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! With that, you built a Flower client, customized it's instantiation through the `client_fn`, customized the server-side execution through a `FedAvg` strategy configured for this workload, and started a simulation with 5 clients (each holding their own individual partition of the Titanic dataset).\n",
    "\n",
    "Next, you can continue to explore more advanced Flower topics:\n",
    "\n",
    "- Deploy server and clients on different machines using `start_server` and `start_client`\n",
    "- Customize the server-side execution through custom strategies\n",
    "- Customize the client-side execution through `config` dictionaries\n",
    "\n",
    "Get all resources you need!\n",
    "\n",
    "* **[DOCS]** Our complete documenation: https://flower.ai/docs/\n",
    "* **[Examples]** All Flower examples: https://flower.ai/docs/examples/\n",
    "* **[VIDEO]** Our Youtube channel: https://www.youtube.com/@flowerlabs\n",
    "\n",
    "Don't forget to join our Slack channel: https://flower.ai/join-slack/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "flower.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
