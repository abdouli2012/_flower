{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "from collections import OrderedDict\n",
    "\n",
    "import flwr as fl\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {DEVICE} for inference')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load CIFAR-10 (training and test set).\"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])]\n",
    "    )\n",
    "\n",
    "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "    num_examples = {\"trainset\": len(trainset), \"testset\": len(testset)}\n",
    "    return trainset, testset, num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_partition(idx: int):\n",
    "    \"\"\"Load 1/10th of the training and test data to simulate a partition.\"\"\"\n",
    "    assert idx in range(10)\n",
    "    trainset, testset, num_examples = load_data()\n",
    "    n_train = int(num_examples['trainset']/10)\n",
    "    n_test = int(num_examples['testset']/10)\n",
    "\n",
    "    train_parition = torch.utils.data.Subset(\n",
    "        trainset, range(idx * n_train,  (idx + 1) * n_train)\n",
    "        )\n",
    "    test_parition = torch.utils.data.Subset(\n",
    "        testset, range(idx * n_test,  (idx + 1) * n_test)\n",
    "    )\n",
    "    return  (train_parition, test_parition)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, valloader, epochs):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "    optimizer = torch.optim.SGD(\n",
    "        net.parameters(), lr=0.1,\n",
    "        momentum=0.9,\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "    net.train()\n",
    "    for _ in range(epochs):\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    train_loss, train_acc =  test(net, trainloader)\n",
    "    val_loss, val_acc = test(net, valloader)\n",
    "\n",
    "    results = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_accuracy\": val_acc,\n",
    "    }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, testloader):\n",
    "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_classifying_layer(efficientnet_model, num_classes: int = 10):\n",
    "    num_features = efficientnet_model.classifier.fc.in_features\n",
    "    efficientnet_model.classifier.fc = torch.nn.Linear(num_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarClient(fl.client.NumPyClient):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: torch.nn.Module,\n",
    "        trainset: torchvision.datasets, \n",
    "        testset: torchvision.datasets,\n",
    "        validation_split:int = 0.1,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.trainset = trainset\n",
    "        self.testset = testset\n",
    "        self.validation_split = validation_split  \n",
    "\n",
    "    def get_parameters(self):\n",
    "        \"\"\"Get parameters of the local model.\"\"\"\n",
    "        raise Exception(\"Not implemented (server-side parameter initialization)\")\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"Train parameters on the locally held training set.\"\"\"\n",
    "\n",
    "        # Update local model parameters\n",
    "        self.set_parameters(parameters)\n",
    "\n",
    "        # Get hyperparameters for this round\n",
    "        batch_size: int = config[\"batch_size\"]\n",
    "        epochs: int = config[\"local_epochs\"]\n",
    "\n",
    "        n_valset =  int(len(self.trainset)*self.validation_split)\n",
    "\n",
    "        valset = torch.utils.data.Subset(\n",
    "            self.trainset, range(0, n_valset)\n",
    "        )\n",
    "        trainset = torch.utils.data.Subset(\n",
    "            self.trainset, range(n_valset, len(self.trainset))\n",
    "        )\n",
    "\n",
    "        trainLoader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "        valLoader = DataLoader(valset, batch_size=batch_size)\n",
    "\n",
    "        results = train(self.model, trainLoader, valLoader, epochs)\n",
    "\n",
    "        parameters_prime = [val.cpu().numpy()\n",
    "                            for _, val in self.model.state_dict().items()]\n",
    "        num_examples_train = len(trainset)\n",
    "\n",
    "        return parameters_prime, num_examples_train, results\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        \"\"\"Evaluate parameters on the locally held test set.\"\"\"\n",
    "        # Update local model parameters\n",
    "        self.set_parameters(parameters)\n",
    "\n",
    "        # Get config values\n",
    "        steps: int = config[\"val_steps\"]\n",
    "        \n",
    "        # Evaluate global model parameters on the local test data and return results\n",
    "        testloader = DataLoader(self.testset, batch_size=steps)\n",
    "\n",
    "        loss, accuracy = test(self.model, testloader)\n",
    "        return float(loss), len(self.testset), {\"accuracy\": float(accuracy)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_efficientnet(entrypoint: str = \"nvidia_efficientnet_b0\", classes:int =  None):\n",
    "    efficientnet = torch.hub.load(\n",
    "        'NVIDIA/DeepLearningExamples:torchhub', entrypoint, pretrained=True)\n",
    "    efficientnet.to(DEVICE)\n",
    "    if classes is not None:\n",
    "        replace_classifying_layer(efficientnet, classes)\n",
    "    return efficientnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_dry_run():\n",
    "    model = load_efficientnet(classes=10)\n",
    "    trainset, testset = load_partition(0)\n",
    "    trainset = torch.utils.data.Subset(\n",
    "        trainset, range(10)\n",
    "    )\n",
    "    testset = torch.utils.data.Subset(\n",
    "        testset, range(10)\n",
    "    )\n",
    "    client = CifarClient(model, trainset, testset)\n",
    "    _fit = client.fit(\n",
    "        [val.cpu().numpy()\n",
    "         for _, val in model.state_dict().items()],\n",
    "        {'batch_size': 32, 'local_epochs': 1})\n",
    "    print(_fit)\n",
    "    _eval = client.evaluate([val.cpu().numpy()\n",
    "                     for _, val in model.state_dict().items()],\n",
    "                    {'val_steps': 32})\n",
    "    print(_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_dry_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains, tests = load_partition(0)\n",
    "trains = torch.utils.data.Subset(\n",
    "    trains, range(10)\n",
    ")\n",
    "EFFICIENTNET_MODEL = 'nvidia_efficientnet_b0'\n",
    "\n",
    "efficientnet = torch.hub.load(\n",
    "    'NVIDIA/DeepLearningExamples:torchhub', EFFICIENTNET_MODEL, pretrained=True)\n",
    "efficientnet.to(DEVICE)\n",
    "replace_classifying_layer(efficientnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23abe26b519aea4b51e9467097d57d1f2c7dd62e2544367eb1239b51ddb64fe9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('flrdev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
